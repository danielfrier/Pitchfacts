{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "import codecs\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import gensim\n",
    "\n",
    "from nltk.corpus import *\n",
    "from collections import *\n",
    "from gensim import *\n",
    "from gensim.models import *\n",
    "from sklearn import *\n",
    "from sklearn.metrics.pairwise import *\n",
    "from nltk.stem import *\n",
    "\n",
    "\n",
    "\n",
    "metadatadf = pd.read_csv('data/metadata.csv', skipinitialspace=True)\n",
    "reviewsdf = pd.read_csv('data/reviews.csv', skipinitialspace=True)\n",
    "# subdf = pd.read_csv('data/subgenres.csv',skipinitialspace=True)\n",
    "\n",
    "dictionary = corpora.Dictionary.load('models/reviewsDict.dict')\n",
    "corpus = corpora.MmCorpus('models/reviewsDict.mm')\n",
    "originaldict = corpora.Dictionary.load('models/orig_text.dict')\n",
    "originalcorp = corpora.MmCorpus('models/orig_text.mm')\n",
    "\n",
    "wem = Word2Vec.load('models/wem/truedata.wem')\n",
    "lda = LdaModel.load('models/lda/lda.lda')\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "genres = ['rap','electronic','metal','rock','experimental','pop','r&b','folk','country','jazz','global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models(topic_num):\n",
    "    lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=topic_num)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary, num_topics=topic_num)\n",
    "    return {'lsi':lsi,'lda':lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(model,a,b,c):\n",
    "    return model.wv.most_similar(positive=[c, b], negative=[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(model, a,b):\n",
    "    return model.wv.similarity(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analogy(wem,'rap','hip-hop','folk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity(wem,'rap','country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(model,word,n):\n",
    "    return model.wv.most_similar(word,topn=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subgenres = {}\n",
    "for i in genres:\n",
    "    subgenres[i]=get_similar(wem,i,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genre_distances = {'rows':genres}\n",
    "for i in genres:\n",
    "    genre_distances[i]=[]\n",
    "    for o in genres:\n",
    "        genre_distances[i].append(o,similarity(wem,i,o))\n",
    " for i in genre_distances:\n",
    "     genre_distances[i].sort(key=lambda tup: tup[1])\n",
    "distancesdf = pd.DataFrame.from_dict(genre_distances)\n",
    "distancesdf.to_csv('genre_distances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distinctiveness = []\n",
    "for i in genre_distances:\n",
    "    distinctiveness.append((i,np.mean([1-o[1] for o in genre_distances[i]])))\n",
    "distinctiveness.sort(key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distinctiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subdf = pd.DataFrame()\n",
    "genrestemp = []\n",
    "substemp = []\n",
    "valstemp = []\n",
    "for i in subgenres:\n",
    "    genrestemp.extend(((i+' ')*(len(subgenres[i])-1)).split(' '))\n",
    "    substemp.extend([o[0] for o in subgenres[i]])\n",
    "    \n",
    "subdf['genre'] = genrestemp\n",
    "subdf['subgenre'] = substemp\n",
    "subdf.to_csv('subgenres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subgenres = {}\n",
    "for row in subdf.iterrows():\n",
    "    if row[1].genre not in subgenres:\n",
    "        subgenres[row[1].genre] = []\n",
    "    subgenres[row[1].genre].append(row[1].subgenre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subs_corr = {}\n",
    "for i in subgenres:\n",
    "    subs_corr[i] = {}\n",
    "    for o in subgenres[i]:\n",
    "        subs_corr[i][o]=[]\n",
    "        for p in subgenres[i]:\n",
    "            subs_corr[i][o].append(round(similarity(wem,o,p),5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in genres:\n",
    "    if i=='global':continue\n",
    "    tempdf = pd.DataFrame()\n",
    "    for o in subgenres[i]:\n",
    "        tempdf[o] = subs_corr[i][o]\n",
    "    tempdf.set_axis(subgenres[i])\n",
    "    tempdf.to_csv(i+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviewsdf.review\n",
    "reviews = [str(i).split() for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "lsa.save('models/twodlsa.lsi')\n",
    "vectorized_corpus = lsa[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreslist = [metadatadf.loc[i].genre for i in list(range(19555))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13300\n",
      "17166\n"
     ]
    }
   ],
   "source": [
    "coordinates = []\n",
    "for i in np.arange(len(vectorized_corpus)):\n",
    "    try:\n",
    "        coordinates.append((i,metadatadf.loc[i].album,metadatadf.loc[i].genre,vectorized_corpus[i][0][1],vectorized_corpus[i][1][1]))\n",
    "    except:\n",
    "        print(i)\n",
    "coordinatesdf = pd.DataFrame.from_records(coordinates)\n",
    "coordinatesdf.columns = ['doc_id','album','genre','x','y']\n",
    "coordinatesdf.set_index('doc_id')\n",
    "coordinatesdf.to_csv('models/lsa_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice_topics(model):\n",
    "    num_topics = len(model.get_topics())\n",
    "    return str(num_topics)+'\\n'+('\\n\\n'.join([model.print_topic(i) for i in list(range(num_topics))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models_list = [generate_models(i) for i in list(range(5,40))]\n",
    "lsafile = open('models/lsa.txt', 'w')\n",
    "ldafile = open('models/lda.txt', 'w')\n",
    "for i in list(range(len(models_list))):\n",
    "    lsafile.write(get_nice_topics(models_list[i]['lsi']))\n",
    "    ldafile.write(get_nice_topics(models_list[i]['lda']))\n",
    "    lsafile.write('\\n\\n')\n",
    "    ldafile.write('\\n\\n')\n",
    "lsafile.close()\n",
    "ldafile.close()\n",
    "for i in list(range(len(models_list))):\n",
    "    (models_list[i]['lsi']).save('models/lsa/'+str(i)+'.lsi')\n",
    "    (models_list[i]['lda']).save('models/lda/'+str(i)+'.lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(get_nice_topics(lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\") as f:\n",
    "    stopwords = [word for line in f for word in line.split()]\n",
    "def remove_stop(m):\n",
    "    return '' if m.group() in stopwords else m.group()\n",
    "def clean_text(text):\n",
    "    temp = text\n",
    "    temp=re.sub('\\S+[\\'\\’\\‘]\\S+','',(temp))\n",
    "    temp=re.sub('\\w*\\d\\S*','',(temp))\n",
    "    temp=re.sub('(?<!^|$)(?<!([(\\.)(\\!)(\\?)(\\“)]\\s))([A-Z]\\S+)','',(temp))\n",
    "    temp=re.sub('[^A-z\\s\\-\\–\\&]',' ',(temp))\n",
    "    temp=re.sub('\\su\\ss\\s',' U.S. ',(temp))\n",
    "    temp=re.sub('\\[#.+]\\|+','',(temp))\n",
    "    temp = temp.lower()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\") as f:\n",
    "    stopwords = [word for line in f for word in line.split()]\n",
    "def remove_stop(m):\n",
    "    return '' if m.group() in stopwords else m.group()\n",
    "def clean_text(text):\n",
    "    temp = text\n",
    "    temp=re.sub('\\S+[\\'\\’\\‘]\\S+','',(temp))\n",
    "    temp=re.sub('\\w*\\d\\S*','',(temp))\n",
    "    temp=re.sub('(?<!^|$)(?<!([(\\.)(\\!)(\\?)(\\“)]\\s))([A-Z]\\S+)','',(temp))\n",
    "    temp=re.sub('[^A-z\\s\\-\\–\\&]',' ',(temp))\n",
    "    temp=re.sub('\\su\\ss\\s',' U.S. ',(temp))\n",
    "    temp=re.sub('\\[#.+]\\|+','',(temp))\n",
    "    temp = temp.lower()\n",
    "    return temp\n",
    "yackreview = re.sub('[\\s\\n\\r\\t]+',' ',re.sub(r'\\w+(\\-|\\—|\\.|\\&|\\’)?(\\w+)?', remove_stop, clean_text(yackreview))).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaltext = ' '.join([' '.join(reviews[i]) for i in list(range(len(reviews)))])\n",
    "totaltext = totaltext.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yackvec_bow = dictionary.doc2bow(yackreview)\n",
    "yackvec_lda = lda[yackvec_bow]\n",
    "totalvec_lda = [(0, 0.032843836), (1, 0.04208189), (2, 0.10474158), (5, 0.042373378), (6, 0.013250324), (9, 0.036808446), (11, 0.023320341), (12, 0.021665176), (14, 0.10429024), (15, 0.030837856), (16, 0.017426088), (18, 0.018971419), (20, 0.049614906), (21, 0.018747063), (22, 0.11087632), (26, 0.14842194), (28, 0.010651322), (33, 0.032480825), (35, 0.07782937)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores = []\n",
    "for i in np.arange(len(reviews)):\n",
    "    sampvec_bow = dictionary.doc2bow(reviews[i])\n",
    "    sampvec_lda = lda[sampvec_bow]\n",
    "    dense1 = gensim.matutils.sparse2full(sampvec_lda, lda.num_topics)\n",
    "    dense2 = gensim.matutils.sparse2full(totalvec_lda, lda.num_topics)\n",
    "    sim = np.sqrt(0.5 * ((np.sqrt(dense1) - np.sqrt(dense2))**2).sum())\n",
    "    scores.append(sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
